{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import Models.Reversible_Classifier as MC\n",
    "import Models.Net as Net\n",
    "\n",
    "import Data_Handler.Classifier_data as CD\n",
    "\n",
    "Classifier_data = CD.Classifier_data\n",
    "CNet = MC.Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Data'\n",
    "g = pd.read_csv(os.path.join(data_dir, \n",
    "    'LupusGeneExpressionCompendium_AllGfeatures.csv'))\n",
    "l = pd.read_csv(os.path.join(data_dir,\n",
    "    'PatientDx_Labels.csv'))\n",
    "\n",
    "df = pd.DataFrame({'trt':[0,1,2], 'sle_class':['Healthy_No_Treatment','SLE_No_Treatment', 'SLE_Treatment']})\n",
    "#Merge the dataframe created with the labels dataset\n",
    "df2 = pd.merge(l, df, how='outer', on='sle_class', left_on=None, right_on=None, left_index=False, right_index=False, sort=True, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n",
    "\n",
    "#Merge all datasets together\n",
    "#research ready dataset\n",
    "df3 = pd.merge(g, df2, how='inner', on='patid', left_on=None, right_on=None, left_index=False, right_index=False, sort=True, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n",
    "\n",
    "#split the dataset into data and labels\n",
    "\n",
    "df_data = df3.iloc[:,1:-2]\n",
    "df_labels = df3.loc[:, 'trt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the imported libraries (optional)\n",
    "importlib.reload(MC)\n",
    "importlib.reload(Net)\n",
    "importlib.reload(CD)\n",
    "\n",
    "CNet = MC.Classifier\n",
    "Classifier_data = CD.Classifier_data\n",
    "\n",
    "# Call the Classifier_Data class with LupusGeneExpressionCompendium_AllGfeatures dataset\n",
    "# Batch_size = 100\n",
    "Lupus_data = Classifier_data(100, df_data.values, df_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split with 945 members\n",
      "Split with 315 members\n",
      "Split with 316 members\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roopal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 782, 1: 782, 2: 782}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roopal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 254, 1: 254, 2: 254}\n",
      "{'random_seed': 123123123, 'result_dir': './results', 'data_dir': './Data', 'report_dir': './summaries', 'hyperparameters': {'Classifier': {'max_epochs': 30, 'lr': 0.0003, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08, 'l2': 0.0}, 'Generator': {'max_epochs': 30, 'lr': 0.0003, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08, 'alpha': 1.0}}, 'graph': {'layers': [15835, 512, 256, 128, 3], 'nonlinearities': ['lrelu', 'lrelu', 'lrelu', 'none'], 'G_layers': [128, 256, 512], 'G_nonlinearities': ['lrelu', 'lrelu', 'lrelu', 'relu'], 'depth': 1}}\n"
     ]
    }
   ],
   "source": [
    "#Specify number of classes and features\n",
    "N_outputs = Lupus_data.Num_of_classes\n",
    "N_inputs = Lupus_data.Num_of_features\n",
    "config = CNet.get_default_configs(N_inputs, N_outputs)\n",
    "# config['hyperparameter']['lr'] = 3e-5\n",
    "cnet = CNet(config, Lupus_data, [0.6, 0.2])\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Variables with seed = 123123123\n",
      "Starting Epoch 1 of 100\n",
      "\tEpoch Completed.  Training loss:   22.56437\n",
      "Starting Epoch 2 of 100\n",
      "\tEpoch Completed.  Training loss:   64.79817\n",
      "Starting Epoch 3 of 100\n",
      "\tEpoch Completed.  Training loss:   41.68647\n",
      "Starting Epoch 4 of 100\n",
      "\tEpoch Completed.  Training loss:   37.89126\n",
      "Starting Epoch 5 of 100\n",
      "\tEpoch Completed.  Training loss:   27.65114\n",
      "Starting Epoch 6 of 100\n",
      "\tEpoch Completed.  Training loss:   26.10387\n",
      "Starting Epoch 7 of 100\n",
      "\tEpoch Completed.  Training loss:   21.97616\n",
      "Starting Epoch 8 of 100\n",
      "\tEpoch Completed.  Training loss:   21.07225\n",
      "Starting Epoch 9 of 100\n",
      "\tEpoch Completed.  Training loss:   19.86786\n",
      "Starting Epoch 10 of 100\n",
      "\tEpoch Completed.  Training loss:   18.98543\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    5.45458\n",
      "Confusion Matrix\n",
      "\t [[ 51 121  82]\n",
      "\t [ 25 183  46]\n",
      "\t [  0   0 254]]\n",
      "Starting Epoch 11 of 100\n",
      "\tEpoch Completed.  Training loss:   18.41162\n",
      "Starting Epoch 12 of 100\n",
      "\tEpoch Completed.  Training loss:   17.97663\n",
      "Starting Epoch 13 of 100\n",
      "\tEpoch Completed.  Training loss:   17.77446\n",
      "Starting Epoch 14 of 100\n",
      "\tEpoch Completed.  Training loss:   17.18558\n",
      "Starting Epoch 15 of 100\n",
      "\tEpoch Completed.  Training loss:   16.60883\n",
      "Starting Epoch 16 of 100\n",
      "\tEpoch Completed.  Training loss:   16.21449\n",
      "Starting Epoch 17 of 100\n",
      "\tEpoch Completed.  Training loss:   16.05876\n",
      "Starting Epoch 18 of 100\n",
      "\tEpoch Completed.  Training loss:   15.60465\n",
      "Starting Epoch 19 of 100\n",
      "\tEpoch Completed.  Training loss:   15.47264\n",
      "Starting Epoch 20 of 100\n",
      "\tEpoch Completed.  Training loss:   14.85599\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    4.00799\n",
      "Confusion Matrix\n",
      "\t [[149  85  20]\n",
      "\t [ 24 214  16]\n",
      "\t [  4   0 250]]\n",
      "Starting Epoch 21 of 100\n",
      "\tEpoch Completed.  Training loss:   14.83013\n",
      "Starting Epoch 22 of 100\n",
      "\tEpoch Completed.  Training loss:   14.58942\n",
      "Starting Epoch 23 of 100\n",
      "\tEpoch Completed.  Training loss:   14.02519\n",
      "Starting Epoch 24 of 100\n",
      "\tEpoch Completed.  Training loss:   14.33502\n",
      "Starting Epoch 25 of 100\n",
      "\tEpoch Completed.  Training loss:   13.31333\n",
      "Starting Epoch 26 of 100\n",
      "\tEpoch Completed.  Training loss:   13.25922\n",
      "Starting Epoch 27 of 100\n",
      "\tEpoch Completed.  Training loss:   13.12033\n",
      "Starting Epoch 28 of 100\n",
      "\tEpoch Completed.  Training loss:   12.42439\n",
      "Starting Epoch 29 of 100\n",
      "\tEpoch Completed.  Training loss:   12.75337\n",
      "Starting Epoch 30 of 100\n",
      "\tEpoch Completed.  Training loss:   12.05947\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    2.95110\n",
      "Confusion Matrix\n",
      "\t [[239  11   4]\n",
      "\t [ 19 226   9]\n",
      "\t [  7   0 247]]\n",
      "Starting Epoch 31 of 100\n",
      "\tEpoch Completed.  Training loss:   11.29174\n",
      "Starting Epoch 32 of 100\n",
      "\tEpoch Completed.  Training loss:   11.55110\n",
      "Starting Epoch 33 of 100\n",
      "\tEpoch Completed.  Training loss:   11.68622\n",
      "Starting Epoch 34 of 100\n",
      "\tEpoch Completed.  Training loss:   10.68934\n",
      "Starting Epoch 35 of 100\n",
      "\tEpoch Completed.  Training loss:   10.60430\n",
      "Starting Epoch 36 of 100\n",
      "\tEpoch Completed.  Training loss:   10.63276\n",
      "Starting Epoch 37 of 100\n",
      "\tEpoch Completed.  Training loss:    9.78984\n",
      "Starting Epoch 38 of 100\n",
      "\tEpoch Completed.  Training loss:    9.57107\n",
      "Starting Epoch 39 of 100\n",
      "\tEpoch Completed.  Training loss:    9.13257\n",
      "Starting Epoch 40 of 100\n",
      "\tEpoch Completed.  Training loss:    9.06780\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    2.17817\n",
      "Confusion Matrix\n",
      "\t [[247   7   0]\n",
      "\t [ 26 219   9]\n",
      "\t [  9   0 245]]\n",
      "Starting Epoch 41 of 100\n",
      "\tEpoch Completed.  Training loss:    8.62184\n",
      "Starting Epoch 42 of 100\n",
      "\tEpoch Completed.  Training loss:    8.40089\n",
      "Starting Epoch 43 of 100\n",
      "\tEpoch Completed.  Training loss:    8.15711\n",
      "Starting Epoch 44 of 100\n",
      "\tEpoch Completed.  Training loss:    7.65545\n",
      "Starting Epoch 45 of 100\n",
      "\tEpoch Completed.  Training loss:    7.25417\n",
      "Starting Epoch 46 of 100\n",
      "\tEpoch Completed.  Training loss:    7.32216\n",
      "Starting Epoch 47 of 100\n",
      "\tEpoch Completed.  Training loss:    6.71995\n",
      "Starting Epoch 48 of 100\n",
      "\tEpoch Completed.  Training loss:    6.65189\n",
      "Starting Epoch 49 of 100\n",
      "\tEpoch Completed.  Training loss:    6.18656\n",
      "Starting Epoch 50 of 100\n",
      "\tEpoch Completed.  Training loss:    6.02445\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    1.67240\n",
      "Confusion Matrix\n",
      "\t [[247   7   0]\n",
      "\t [ 25 221   8]\n",
      "\t [  9   0 245]]\n",
      "Starting Epoch 51 of 100\n",
      "\tEpoch Completed.  Training loss:    5.77989\n",
      "Starting Epoch 52 of 100\n",
      "\tEpoch Completed.  Training loss:    5.71384\n",
      "Starting Epoch 53 of 100\n",
      "\tEpoch Completed.  Training loss:    5.43679\n",
      "Starting Epoch 54 of 100\n",
      "\tEpoch Completed.  Training loss:    5.34972\n",
      "Starting Epoch 55 of 100\n",
      "\tEpoch Completed.  Training loss:    5.05881\n",
      "Starting Epoch 56 of 100\n",
      "\tEpoch Completed.  Training loss:    5.01079\n",
      "Starting Epoch 57 of 100\n",
      "\tEpoch Completed.  Training loss:    4.80969\n",
      "Starting Epoch 58 of 100\n",
      "\tEpoch Completed.  Training loss:    4.70787\n",
      "Starting Epoch 59 of 100\n",
      "\tEpoch Completed.  Training loss:    4.54186\n",
      "Starting Epoch 60 of 100\n",
      "\tEpoch Completed.  Training loss:    4.44935\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    1.39960\n",
      "Confusion Matrix\n",
      "\t [[247   7   0]\n",
      "\t [ 19 227   8]\n",
      "\t [  8   0 246]]\n",
      "Starting Epoch 61 of 100\n",
      "\tEpoch Completed.  Training loss:    4.31354\n",
      "Starting Epoch 62 of 100\n",
      "\tEpoch Completed.  Training loss:    4.19787\n",
      "Starting Epoch 63 of 100\n",
      "\tEpoch Completed.  Training loss:    4.07171\n",
      "Starting Epoch 64 of 100\n",
      "\tEpoch Completed.  Training loss:    3.96115\n",
      "Starting Epoch 65 of 100\n",
      "\tEpoch Completed.  Training loss:    3.86145\n",
      "Starting Epoch 66 of 100\n",
      "\tEpoch Completed.  Training loss:    3.73965\n",
      "Starting Epoch 67 of 100\n",
      "\tEpoch Completed.  Training loss:    3.62762\n",
      "Starting Epoch 68 of 100\n",
      "\tEpoch Completed.  Training loss:    3.53987\n",
      "Starting Epoch 69 of 100\n",
      "\tEpoch Completed.  Training loss:    3.46351\n",
      "Starting Epoch 70 of 100\n",
      "\tEpoch Completed.  Training loss:    3.39232\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    1.24031\n",
      "Confusion Matrix\n",
      "\t [[246   8   0]\n",
      "\t [ 12 234   8]\n",
      "\t [  6   0 248]]\n",
      "Starting Epoch 71 of 100\n",
      "\tEpoch Completed.  Training loss:    3.31814\n",
      "Starting Epoch 72 of 100\n",
      "\tEpoch Completed.  Training loss:    3.23807\n",
      "Starting Epoch 73 of 100\n",
      "\tEpoch Completed.  Training loss:    3.14209\n",
      "Starting Epoch 74 of 100\n",
      "\tEpoch Completed.  Training loss:    3.05028\n",
      "Starting Epoch 75 of 100\n",
      "\tEpoch Completed.  Training loss:    2.96651\n",
      "Starting Epoch 76 of 100\n",
      "\tEpoch Completed.  Training loss:    2.89250\n",
      "Starting Epoch 77 of 100\n",
      "\tEpoch Completed.  Training loss:    2.82799\n",
      "Starting Epoch 78 of 100\n",
      "\tEpoch Completed.  Training loss:    2.75877\n",
      "Starting Epoch 79 of 100\n",
      "\tEpoch Completed.  Training loss:    2.69818\n",
      "Starting Epoch 80 of 100\n",
      "\tEpoch Completed.  Training loss:    2.63170\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    1.13029\n",
      "Confusion Matrix\n",
      "\t [[246   8   0]\n",
      "\t [  9 237   8]\n",
      "\t [  3   0 251]]\n",
      "Starting Epoch 81 of 100\n",
      "\tEpoch Completed.  Training loss:    2.57765\n",
      "Starting Epoch 82 of 100\n",
      "\tEpoch Completed.  Training loss:    2.52604\n",
      "Starting Epoch 83 of 100\n",
      "\tEpoch Completed.  Training loss:    2.47424\n",
      "Starting Epoch 84 of 100\n",
      "\tEpoch Completed.  Training loss:    2.42959\n",
      "Starting Epoch 85 of 100\n",
      "\tEpoch Completed.  Training loss:    2.38880\n",
      "Starting Epoch 86 of 100\n",
      "\tEpoch Completed.  Training loss:    2.34259\n",
      "Starting Epoch 87 of 100\n",
      "\tEpoch Completed.  Training loss:    2.30290\n",
      "Starting Epoch 88 of 100\n",
      "\tEpoch Completed.  Training loss:    2.25926\n",
      "Starting Epoch 89 of 100\n",
      "\tEpoch Completed.  Training loss:    2.22025\n",
      "Starting Epoch 90 of 100\n",
      "\tEpoch Completed.  Training loss:    2.18160\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    1.07869\n",
      "Confusion Matrix\n",
      "\t [[246   8   0]\n",
      "\t [  6 240   8]\n",
      "\t [  1   0 253]]\n",
      "Starting Epoch 91 of 100\n",
      "\tEpoch Completed.  Training loss:    2.14349\n",
      "Starting Epoch 92 of 100\n",
      "\tEpoch Completed.  Training loss:    2.10881\n",
      "Starting Epoch 93 of 100\n",
      "\tEpoch Completed.  Training loss:    2.07198\n",
      "Starting Epoch 94 of 100\n",
      "\tEpoch Completed.  Training loss:    2.03579\n",
      "Starting Epoch 95 of 100\n",
      "\tEpoch Completed.  Training loss:    2.00838\n",
      "Starting Epoch 96 of 100\n",
      "\tEpoch Completed.  Training loss:    1.97920\n",
      "Starting Epoch 97 of 100\n",
      "\tEpoch Completed.  Training loss:    1.95363\n",
      "Starting Epoch 98 of 100\n",
      "\tEpoch Completed.  Training loss:    1.92644\n",
      "Starting Epoch 99 of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch Completed.  Training loss:    1.89832\n",
      "Starting Epoch 100 of 100\n",
      "\tEpoch Completed.  Training loss:    1.87556\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    1.05567\n",
      "Confusion Matrix\n",
      "\t [[245   9   0]\n",
      "\t [  6 240   8]\n",
      "\t [  0   0 254]]\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    1.05567\n",
      "Confusion Matrix\n",
      "\t [[245   9   0]\n",
      "\t [  6 240   8]\n",
      "\t [  0   0 254]]\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier using optimized hyperparameter values\n",
    "Hp_values = list([0.00228315,0.8978787,0.0020122,0.6406958,1.056737e-05])\n",
    "Hp_names = ['lr', 'beta1', 'beta2', 'epsilon', 'max_epochs', 'l2_penalty']\n",
    "Hp = dict(zip(Hp_names, Hp_values))\n",
    "Hp['max_epochs'] = 100\n",
    "\n",
    "cnet.train(save_every=0, eval_every=10, hyperparameters=Hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.278296, 'beta1': 0.212388, 'beta2': 0.340391, 'epsilon': 0.142364, 'max_epochs': 60, 'alpha': 0.05}\n",
      "starting Epoch 1 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00192\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.09152\n",
      "Confusion Matrix\n",
      "\t [[254   0   0]\n",
      "\t [254   0   0]\n",
      "\t [254   0   0]]\n",
      "starting Epoch 2 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00200\n",
      "starting Epoch 3 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00120\n",
      "starting Epoch 4 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00102\n",
      "starting Epoch 5 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00095\n",
      "starting Epoch 6 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00092\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00228\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  6 240   8]\n",
      "\t [  0   0 254]]\n",
      "starting Epoch 7 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00090\n",
      "starting Epoch 8 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00088\n",
      "starting Epoch 9 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00087\n",
      "starting Epoch 10 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00086\n",
      "starting Epoch 11 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00085\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00222\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  6 240   8]\n",
      "\t [  0   0 254]]\n",
      "starting Epoch 12 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00084\n",
      "starting Epoch 13 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00083\n",
      "starting Epoch 14 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00082\n",
      "starting Epoch 15 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00081\n",
      "starting Epoch 16 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00080\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00218\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  6 240   8]\n",
      "\t [  0   0 254]]\n",
      "starting Epoch 17 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00079\n",
      "starting Epoch 18 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00078\n",
      "starting Epoch 19 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00077\n",
      "starting Epoch 20 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00076\n",
      "starting Epoch 21 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00075\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00216\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  6 240   8]\n",
      "\t [  1   0 253]]\n",
      "starting Epoch 22 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00074\n",
      "starting Epoch 23 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00073\n",
      "starting Epoch 24 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00073\n",
      "starting Epoch 25 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00072\n",
      "starting Epoch 26 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00071\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00215\n",
      "Confusion Matrix\n",
      "\t [[245   9   0]\n",
      "\t [  6 240   8]\n",
      "\t [  1   0 253]]\n",
      "starting Epoch 27 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00070\n",
      "starting Epoch 28 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00070\n",
      "starting Epoch 29 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00069\n",
      "starting Epoch 30 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00068\n",
      "starting Epoch 31 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00068\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00216\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  6 240   8]\n",
      "\t [  2   0 252]]\n",
      "starting Epoch 32 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00067\n",
      "starting Epoch 33 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00067\n",
      "starting Epoch 34 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00066\n",
      "starting Epoch 35 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00066\n",
      "starting Epoch 36 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00065\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00215\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  5 241   8]\n",
      "\t [  1   0 253]]\n",
      "starting Epoch 37 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00065\n",
      "starting Epoch 38 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00065\n",
      "starting Epoch 39 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00064\n",
      "starting Epoch 40 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00064\n",
      "starting Epoch 41 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00064\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00213\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  5 241   8]\n",
      "\t [  1   0 253]]\n",
      "starting Epoch 42 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00063\n",
      "starting Epoch 43 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00063\n",
      "starting Epoch 44 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00063\n",
      "starting Epoch 45 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00062\n",
      "starting Epoch 46 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00062\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00211\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  5 241   8]\n",
      "\t [  1   0 253]]\n",
      "starting Epoch 47 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00062\n",
      "starting Epoch 48 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00061\n",
      "starting Epoch 49 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00061\n",
      "starting Epoch 50 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00061\n",
      "starting Epoch 51 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00061\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00208\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  5 241   8]\n",
      "\t [  0   0 254]]\n",
      "starting Epoch 52 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00060\n",
      "starting Epoch 53 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00060\n",
      "starting Epoch 54 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00060\n",
      "starting Epoch 55 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00060\n",
      "starting Epoch 56 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00060\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00206\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  5 241   8]\n",
      "\t [  0   0 254]]\n",
      "starting Epoch 57 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00059\n",
      "starting Epoch 58 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00059\n",
      "starting Epoch 59 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00059\n",
      "starting Epoch 60 of 60\n",
      "\tEpoch Completed.  Training loss:    0.00059\n",
      "Evaluating model performance with validation data\n",
      "\t Validation Loss:    0.00205\n",
      "Confusion Matrix\n",
      "\t [[244  10   0]\n",
      "\t [  5 241   8]\n",
      "\t [  0   0 254]]\n"
     ]
    }
   ],
   "source": [
    "### WARNING Generator Training is extremely resource intensive\n",
    "# Train the generator using optimized hyperparameter values\n",
    "Hp_values = list([0.278296,0.212388,0.340391,0.142364,58.039])\n",
    "Hp_names = ['lr', 'beta1', 'beta2', 'epsilon', 'max_epochs', 'l2_penalty']\n",
    "Hp = dict(zip(Hp_names, Hp_values))\n",
    "Hp['max_epochs'] = 60\n",
    "Hp['alpha'] = 0.05\n",
    "print(Hp)\n",
    "\n",
    "cnet.train_generator(save_every = 0, eval_every = 5, hyperparameters = Hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 15835)\n"
     ]
    }
   ],
   "source": [
    "# Get inverse from pseudoinverse\n",
    "# Output = input-like matrix\n",
    "Training_data = cnet.Training_data\n",
    "batch = Training_data.getBatch(0)\n",
    "batch_x = batch['X']\n",
    "inverse_mat = cnet.sess.run(cnet.inverted_hidden_layer,\n",
    "                           feed_dict = {cnet.input: batch_x})\n",
    "\n",
    "print(inverse_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002049928017723279\n"
     ]
    }
   ],
   "source": [
    "print(cnet.val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnet.sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
